# Pipeline d'Automatisation - Syst√®me de Recommandation

## üìã Vue d'ensemble

Ce module g√®re l'automatisation compl√®te du syst√®me de recommandation de publications scientifiques. Il orchestre la mise √† jour des donn√©es, l'am√©lioration continue du mod√®le et le monitoring des performances gr√¢ce √† un pipeline robuste et scalable.

## üèóÔ∏è Architecture

### Composants principaux

- **`pipeline_automatisation.py`** : Script principal orchestrant l'ensemble du pipeline
- **`recommendation_dags.py`** : Configuration des DAGs Apache Airflow pour la planification des t√¢ches
- **MLflow** : Suivi des exp√©riences et versioning des mod√®les
- **MongoDB** : Base de donn√©es pour les publications et l'historique des recherches

### Flux de donn√©es

```
Nouvelles Publications ‚Üí Mise √† jour BD ‚Üí Rafra√Æchissement Mod√®le
                                      ‚Üò
Feedback Utilisateurs ‚Üí Analyse M√©triques ‚Üí Optimisation Mod√®le
                                      ‚Üò
                              Monitoring API ‚Üí Alertes
```

## üöÄ Installation et Configuration

### Pr√©requis

```bash
# D√©pendances Python
pip install apache-airflow mlflow pymongo pandas numpy scikit-learn requests

# Services externes
docker run -d -p 5000:5000 --name mlflow-server mlflow server --host 0.0.0.0
```

### Configuration des r√©pertoires

Le pipeline cr√©e automatiquement les r√©pertoires suivants :
- `model_cache/` : Cache des mod√®les entra√Æn√©s
- `model_cache/logs/` : Journaux d'ex√©cution
- `model_cache/feedback/` : Donn√©es de retour utilisateur

### Variables d'environnement

Assurez-vous que votre fichier `config.py` contient :

```python
MONGO_URI = "mongodb://localhost:27017/"
MONGO_DB_NAME = "recommendation_db"
COLLECTIONS = {
    "publications": "publications",
    "search_history": "SearchHistory"
}
TEST_MODE = False  # True pour les tests
```

## üìä Fonctionnalit√©s

### 1. Mise √† jour automatique des publications

```python
# Ex√©cution manuelle
pipeline = AutomationPipeline()
pipeline.update_publications()
```

**Fonctionnalit√©s :**
- R√©cup√©ration de nouvelles publications depuis sources externes
- Insertion en base de donn√©es MongoDB  
- D√©clenchement automatique du rafra√Æchissement du mod√®le

### 2. Rafra√Æchissement du mod√®le

**Processus automatis√© :**
- Rechargement des publications depuis la BD
- Reconstruction des vecteurs TF-IDF
- Mise en cache du mod√®le optimis√©
- Enregistrement des m√©triques dans MLflow

### 3. Analyse des retours utilisateurs

**M√©triques collect√©es :**
- Nombre total de feedbacks
- Note moyenne des recommandations
- Nombre d'utilisateurs uniques
- Tendances par domaine de recherche

### 4. Optimisation bas√©e sur les performances

Le syst√®me adapte automatiquement les param√®tres du mod√®le selon :
- Les notes utilisateurs (seuil < 3.5/5)
- Le volume de feedback (minimum 10 retours)
- Les m√©triques de performance

### 5. Monitoring de l'API

Surveillance continue de :
- Disponibilit√© du service (endpoint `/health`)
- Temps de r√©ponse
- M√©triques de performance

## üîÑ Orchestration avec Apache Airflow

### DAGs configur√©s

#### 1. `update_publications_daily`
- **Fr√©quence** : Quotidienne
- **Fonction** : Mise √† jour des publications
- **Retry** : 1 tentative avec d√©lai de 5 minutes

#### 2. `refresh_model_weekly`  
- **Fr√©quence** : Hebdomadaire
- **Fonction** : Rafra√Æchissement complet du mod√®le
- **Suivi** : M√©triques MLflow automatiques

#### 3. `monitor_model_performance`
- **Fr√©quence** : Quotidienne  
- **Fonction** : Collecte feedback + optimisation
- **Pipeline** : `collect_user_feedback` ‚Üí `optimize_model`

### D√©marrage d'Airflow

```bash
# Initialiser la base de donn√©es Airflow
airflow db init

# Cr√©er un utilisateur admin
airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com

# D√©marrer le scheduler et le webserver
airflow scheduler &
airflow webserver --port 8080
```

Interface web accessible sur : `http://localhost:8080`

## üìà Monitoring avec MLflow

### Acc√®s √† l'interface

```bash
mlflow ui --host 0.0.0.0 --port 5000
```

Interface web : `http://localhost:5000`

### Exp√©riences track√©es

- **`automation_pipeline`** : M√©triques g√©n√©rales du pipeline
- **`recommandation_publications`** : Performance du mod√®le
- **`recommandation_feedback`** : Analyse des retours utilisateurs
- **`recommandation_optimisation`** : Optimisations appliqu√©es

### M√©triques cl√©s

- Nombre de publications trait√©es
- Pr√©cision du mod√®le de recommandation
- Satisfaction utilisateur moyenne
- Temps de r√©ponse API

## üîß Utilisation

### Ex√©cution compl√®te du pipeline

```python
from pipeline_automatisation import AutomationPipeline

# Initialisation
pipeline = AutomationPipeline()

# Ex√©cution compl√®te
pipeline.run_complete_pipeline()
```

### Ex√©cution de t√¢ches sp√©cifiques

```python
# Mise √† jour des publications uniquement
pipeline.update_publications()

# Rafra√Æchissement du mod√®le
pipeline.refresh_model()

# Analyse des feedbacks
pipeline.analyze_user_feedback()

# Optimisation
pipeline.optimize_model_based_on_feedback()

# V√©rification API
pipeline.monitor_api_health()
```

### Mode de test

Pour les environnements de d√©veloppement :

```python
# Dans config.py
TEST_MODE = True
```

En mode test, aucune donn√©e n'est √©crite en base de donn√©es.

## üìÅ Structure des fichiers

```
automation/
‚îú‚îÄ‚îÄ pipeline_automatisation.py    # Pipeline principal
‚îú‚îÄ‚îÄ recommendation_dags.py        # Configuration Airflow
‚îú‚îÄ‚îÄ model_cache/                  # Cache mod√®les
‚îÇ   ‚îú‚îÄ‚îÄ vectorizer.pkl           # Vectoriseur TF-IDF
‚îÇ   ‚îú‚îÄ‚îÄ publication_vectors.pkl  # Vecteurs publications  
‚îÇ   ‚îú‚îÄ‚îÄ publications_df.pkl      # DataFrame publications
‚îÇ   ‚îú‚îÄ‚îÄ feedback_metrics.json    # M√©triques feedback
‚îÇ   ‚îú‚îÄ‚îÄ logs/                    # Journaux
‚îÇ   ‚îî‚îÄ‚îÄ feedback/                # Donn√©es feedback
‚îî‚îÄ‚îÄ README.md                    # Documentation
```

## üîç Logging et Debugging

### Configuration des logs

Les logs sont automatiquement sauvegard√©s dans :
- Console : Niveau INFO
- Fichier : `pipeline_auto.log` (tous niveaux)

### Debugging des erreurs courantes

**Erreur de connexion MongoDB :**
```python
# V√©rifier la connexion
from pymongo import MongoClient
client = MongoClient("mongodb://localhost:27017/")
client.admin.command('ping')  # Doit retourner {'ok': 1.0}
```

**Erreur MLflow :**
```bash
# Red√©marrer le serveur MLflow
mlflow server --host 0.0.0.0 --port 5000
```

**Mod√®le non trouv√© :**
```python
# Forcer la reconstruction
pipeline.refresh_model()
```

## üö® Monitoring et Alertes

### Indicateurs de sant√©

- ‚úÖ **Vert** : Toutes les t√¢ches s'ex√©cutent normalement
- ‚ö†Ô∏è **Orange** : Avertissements (feedback insuffisant, API lente)
- ‚ùå **Rouge** : Erreurs critiques (API indisponible, √©chec mod√®le)

### Alertes configur√©es

- Email automatique en cas d'√©chec des DAGs Airflow
- Logging d√©taill√© pour diagnostic
- M√©triques MLflow pour suivi continu

## üîÑ Maintenance

### T√¢ches recommand√©es

**Quotidienne :**
- V√©rification des logs d'erreur
- Contr√¥le des m√©triques MLflow

**Hebdomadaire :**
- Nettoyage des anciens logs
- Analyse des tendances de performance

**Mensuelle :**
- Optimisation de la base de donn√©es
- R√©vision des seuils d'alerte

### Mise √† jour

Pour mettre √† jour le pipeline :

1. Arr√™ter les services Airflow
2. D√©ployer les nouveaux fichiers
3. Red√©marrer les services
4. V√©rifier les DAGs dans l'interface web

## üìû Support

En cas de probl√®me :

1. Consulter les logs dans `pipeline_auto.log`
2. V√©rifier l'interface MLflow pour les m√©triques
3. Contr√¥ler les DAGs Airflow pour les √©checs de t√¢ches
4. Tester la connectivit√© MongoDB et API

## üîÆ √âvolutions futures

- Int√©gration de sources de donn√©es suppl√©mentaires
- Algorithmes de recommandation plus sophistiqu√©s
- Tableau de bord temps r√©el pour le monitoring
- Tests d'A/B pour l'optimisation continue
- Scaling horizontal avec Kubernetes